{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truecasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def truecase(experiment_folder):\n",
    "    script = \"/home/samuel/Software/mosesdecoder/scripts/recaser/train-truecaser.perl\"\n",
    "    dev_set = \"/home/samuel/Documents/research_and_development/tweet-norm-dev_\"\n",
    "    \n",
    "    print(\"Learning the truecaser model...\")\n",
    "    for extension in [\"source\", \"target\"]:\n",
    "        !{script} --corpus dev_set{extension}.txt --corpus {experiment_folder}paraphrases.clean.{extension}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lm_counts(input_dir, output_dir):\n",
    "    ''' Create language models counts for all the files in a directory '''\n",
    "    \n",
    "    filenames = os.listdir(input_dir)\n",
    "    for filename in filenames:\n",
    "        !/local/kurs/mt/srilm/bin/i686-m64/ngram-count -kndiscount -text {input_dir}{filename} -lm {ouput_dir}/{filename}.counts -order 5 \n",
    "        #!head n1 {input_dir}{filename}\n",
    "        print(\"Created LM counts for file {filename}\".format(**locals()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_smt(experiment_folder):\n",
    "    script = \"/home/samuel/Software/mosesdecoder/scripts/training/train-model.perl\"\n",
    "    giza = \"/home/samuel/Software/mosesdecoder/tools\"\n",
    "    lm_file = \"/home/samuel/Documents/research_and_development/language_model/lm.gz\"\n",
    "    corpus = \"{experiment_folder}paraphrases.clean\".format(**locals())\n",
    "    \n",
    "    print(\"Training SMT model...\")\n",
    "    !{script} --corpus {corpus} --f source --e target --root-dir {experiment_folder}translation_model/ --lm 0:5:{lm_file} --external-bin-dir {giza} >logfile 2>&1\n",
    "    print(\"SMT model trained.\")\n",
    "    \n",
    "    \n",
    "def tune_smt(experiment_folder):\n",
    "    script = \"/home/samuel/Software/mosesdecoder/scripts/training/mert-moses.pl\"\n",
    "    dev_source = \"/home/samuel/Documents/research_and_development/dev_set/tweet-norm-dev_source.txt\"\n",
    "    dev_target = \"/home/samuel/Documents/research_and_development/dev_set/tweet-norm-dev_target.txt\"\n",
    "    ini_file = \"{experiment_folder}translation_model/model/moses.ini\".format(**locals())\n",
    "    tuning_dir = \"{experiment_folder}tuning/\".format(**locals())\n",
    "    moses = \"/home/samuel/Software/mosesdecoder/bin/moses\"\n",
    "    !mkdir -p {tuning_dir}\n",
    "    \n",
    "    print(\"Tuning SMT model...\")\n",
    "    !{script} {dev_source} {dev_target} {moses} {ini_file} --working-dir {tuning_dir} --mertdir /home/samuel/Software/mosesdecoder/bin >{tuning_dir}logfile.mert 2>&1 --decoder-flags=\"-threads 4\"\n",
    "    print(\"SMT model tuned.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance_test_pruning(experiment_folder):\n",
    "    file = \"{experiment_folder}paraphrases.clean.\"\n",
    "    index_script = \"/home/samuel/Software/salm/Bin/Linux/Index/IndexSA.O64\"\n",
    "    prune_script = \"/home/samuel/Software/mosesdecoder/contrib/sigtest-filter/filter-pt\"\n",
    "    phrase_table_dir = \"{experiment_folder}/tuning/filtered/\"\n",
    "    \n",
    "    print(\"Getting indices...\")\n",
    "    for extension in [\"source\", \"target\"]:\n",
    "        !{index_script} {file}{extension}\n",
    "    \n",
    "    print(\"Unziping phrasetable...\")\n",
    "    !zcat {phrase_table_dir}phrase-table.0-0.1.1.gz > phrase-table\n",
    "    \n",
    "    print(\"Prunning phrasetable...\")\n",
    "    !cat {phrase_table_dir}phrase-table | {prune_script} -e {file}target -f {file}source -l a+e -n 30 > {phrase_table_dir}phrase-table.pruned\n",
    "    print(\"Prunned Phrasetable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Tuned Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tuned(experiment_folder):\n",
    "    !/home/samuel/Software/mosesdecoder/bin/moses -f /home/samuel/Documents/research_and_development/experiment4/tuning/moses.ini < /home/samuel/Documents/research_and_development/dev_set/tweet-norm-dev_source.txt > results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning SMT model...\n",
      "SMT model tuned.\n"
     ]
    }
   ],
   "source": [
    "experiment_folder = \"/home/samuel/Documents/research_and_development/experiment4/\"\n",
    "#train_smt(experiment_folder)\n",
    "tune_smt(experiment_folder)\n",
    "#significance_test_pruning(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
